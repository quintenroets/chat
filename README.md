# Chat
[![PyPI version](https://badge.fury.io/py/powerchat-cli.svg)](https://badge.fury.io/py/powerchat-cli)
![PyPI downloads](https://img.shields.io/pypi/dm/powerchat-cli)
![Python version](https://img.shields.io/badge/python-3.10+-brightgreen)
![Operating system](https://img.shields.io/badge/os-linux%20%7c%20macOS%20%7c%20windows-brightgreen)
![Coverage](https://img.shields.io/badge/coverage-100%25-brightgreen)

![example chat](https://github.com/quintenroets/chat/blob/main/assets/examples/example.png?raw=true)

## Usage

Run
```shell
chat
```
or
```shell
powerchat
```
## Installation
1. [Setup langchain-ollama](https://dev.to/emmakodes_/how-to-run-llama-31-locally-in-python-using-ollama-langchain-k8k)

2. Run `pip install powerchat-cli`
